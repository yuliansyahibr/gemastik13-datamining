{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import ast\n",
    "import sklearn\n",
    "from collections import Counter\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the labeled comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1460"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.read_csv('./data/both_sheet.csv').Sentimen.value_counts()\n",
    "len(pd.read_csv('./data/both_sheet.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_komentar</th>\n",
       "      <th>author_name</th>\n",
       "      <th>text_display</th>\n",
       "      <th>Sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UgxIYgX15ktKkPHD_Jp4AaABAg</td>\n",
       "      <td>Dono Bonek</td>\n",
       "      <td>Mudah\"Han dengan adanya new normal masyarakat ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>UgzPhA5bbqdqFSRnsJ14AaABAg</td>\n",
       "      <td>rita emil</td>\n",
       "      <td>Anak sekolah mulai masuk juga ya,  sempet was ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>UgwmIetxeEQ52ZAk8qt4AaABAg</td>\n",
       "      <td>suratno suratno</td>\n",
       "      <td>new normal / hidup berdampingan/ berdamai deng...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>UgzZ_9wGYyxHqt0rgP14AaABAg</td>\n",
       "      <td>Sola Gaming</td>\n",
       "      <td>Pak Menurut Saya Mending Biarkan Covid 19 Dibi...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>UgyQ0ia5pgwlRFPNARh4AaABAg</td>\n",
       "      <td>Riady Tandy</td>\n",
       "      <td>jga diri kita masing2, ikut anjuran pemerintah...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>Ugwqf5vUXsxJtQmbUrJ4AaABAg</td>\n",
       "      <td>Andry Sacho</td>\n",
       "      <td>Mudah mudahan warga china di larang selamanya ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>UgyVKn6x_U0VJsH9C594AaABAg</td>\n",
       "      <td>fachri yansyah</td>\n",
       "      <td>Mudah-mudahan di tempat ibadah &amp; sekolah sdh n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>Ugz7D1-87joN1zD7YdR4AaABAg</td>\n",
       "      <td>Abu Syuroih</td>\n",
       "      <td>Mudah mudahan allah memudahkan urusan kita...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>UgzUUTPTSRE-9PzmPCd4AaABAg</td>\n",
       "      <td>Patah Kayu</td>\n",
       "      <td>Mudahan yang nonton video ini bersyukur akan k...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id_komentar      author_name  \\\n",
       "11    UgxIYgX15ktKkPHD_Jp4AaABAg       Dono Bonek   \n",
       "117   UgzPhA5bbqdqFSRnsJ14AaABAg        rita emil   \n",
       "166   UgwmIetxeEQ52ZAk8qt4AaABAg  suratno suratno   \n",
       "196   UgzZ_9wGYyxHqt0rgP14AaABAg      Sola Gaming   \n",
       "789   UgyQ0ia5pgwlRFPNARh4AaABAg      Riady Tandy   \n",
       "829   Ugwqf5vUXsxJtQmbUrJ4AaABAg      Andry Sacho   \n",
       "934   UgyVKn6x_U0VJsH9C594AaABAg   fachri yansyah   \n",
       "1033  Ugz7D1-87joN1zD7YdR4AaABAg      Abu Syuroih   \n",
       "1190  UgzUUTPTSRE-9PzmPCd4AaABAg       Patah Kayu   \n",
       "\n",
       "                                           text_display  Sentimen  \n",
       "11    Mudah\"Han dengan adanya new normal masyarakat ...       1.0  \n",
       "117   Anak sekolah mulai masuk juga ya,  sempet was ...       0.0  \n",
       "166   new normal / hidup berdampingan/ berdamai deng...       0.0  \n",
       "196   Pak Menurut Saya Mending Biarkan Covid 19 Dibi...      -1.0  \n",
       "789   jga diri kita masing2, ikut anjuran pemerintah...       1.0  \n",
       "829   Mudah mudahan warga china di larang selamanya ...       0.0  \n",
       "934   Mudah-mudahan di tempat ibadah & sekolah sdh n...       1.0  \n",
       "1033      Mudah mudahan allah memudahkan urusan kita...       0.0  \n",
       "1190  Mudahan yang nonton video ini bersyukur akan k...       0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldf = pd.read_csv('./data/both_sheet.csv')\n",
    "fulldf = fulldf[~fulldf.Sentimen.isna()].reset_index(drop=True)\n",
    "fulldf[fulldf.text_display.str.contains('Mudah')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ambil kolom text and sentimen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   text      1460 non-null   object\n",
      " 1   sentimen  1460 non-null   int32 \n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 17.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# df = fulldf[['id_komentar']].copy()\n",
    "df = pd.DataFrame()\n",
    "df['text'] = fulldf['text_display'].astype(str)\n",
    "df['sentimen'] = fulldf['Sentimen'].astype('int')\n",
    "df = df.reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sekarang saya malu  , kenapa dulu terlalu memb...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Peraturan anehh semua ,,, aku nyaris mati kela...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Semoga covid cepat berlallu..aminðŸ¤² \\nKaltim pu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentimen\n",
       "0  Ya allah musnahkan lah virus corona dr muka bu...         0\n",
       "1  sekarang saya malu  , kenapa dulu terlalu memb...        -1\n",
       "2  Peraturan anehh semua ,,, aku nyaris mati kela...        -1\n",
       "3  Saya selalu nunggu new normal biar saya segera...         1\n",
       "4  Semoga covid cepat berlallu..aminðŸ¤² \\nKaltim pu...         1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df[\"text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentimen</th>\n",
       "      <th>text_wo_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sekarang saya malu  , kenapa dulu terlalu memb...</td>\n",
       "      <td>-1</td>\n",
       "      <td>sekarang saya malu    kenapa dulu terlalu memb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peraturan anehh semua ,,, aku nyaris mati kela...</td>\n",
       "      <td>-1</td>\n",
       "      <td>peraturan anehh semua     aku nyaris mati kela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>1</td>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>semoga covid cepat berlallu..aminðŸ¤² \\nkaltim pu...</td>\n",
       "      <td>1</td>\n",
       "      <td>semoga covid cepat berlallu  aminðŸ¤²  kaltim pun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentimen  \\\n",
       "0  ya allah musnahkan lah virus corona dr muka bu...         0   \n",
       "1  sekarang saya malu  , kenapa dulu terlalu memb...        -1   \n",
       "2  peraturan anehh semua ,,, aku nyaris mati kela...        -1   \n",
       "3  saya selalu nunggu new normal biar saya segera...         1   \n",
       "4  semoga covid cepat berlallu..aminðŸ¤² \\nkaltim pu...         1   \n",
       "\n",
       "                                       text_wo_punct  \n",
       "0  ya allah musnahkan lah virus corona dr muka bu...  \n",
       "1  sekarang saya malu    kenapa dulu terlalu memb...  \n",
       "2  peraturan anehh semua     aku nyaris mati kela...  \n",
       "3  saya selalu nunggu new normal biar saya segera...  \n",
       "4  semoga covid cepat berlallu  aminðŸ¤²  kaltim pun...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removal of Punctuations\n",
    "\n",
    "col_from = \"text\"\n",
    "col_save = \"text_wo_punct\"\n",
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "#     return text.translate(str.maketrans(' ', ' ', PUNCT_TO_REMOVE))\n",
    "#     return text.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
    "    # replace punc with space\n",
    "    text = text.replace('\\n', ' ')\n",
    "#     text = text.replace('\"', ' ')\n",
    "#     text = text.replace(\"'\", ' ')\n",
    "    return text.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
    "    return text\n",
    "\n",
    "df[col_save] = df[col_from].apply(lambda text: remove_punctuation(text))\n",
    "COL = col_save\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hapus \n",
    " - 'wkwkkw', \n",
    " - '\\n', \n",
    " - huruf >1 di akhir kata, 'aminnn'->'amin', 'apaa'->'apa', 'iyaaaa'->'iya'\n",
    " - hurut >2 di kata, 'amiiiin'->'amin', 'sekaraaang'->'sekarang'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentimen</th>\n",
       "      <th>text_wo_punct</th>\n",
       "      <th>text_custom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "      <td>ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sekarang saya malu  , kenapa dulu terlalu memb...</td>\n",
       "      <td>-1</td>\n",
       "      <td>sekarang saya malu    kenapa dulu terlalu memb...</td>\n",
       "      <td>sekarang saya malu kenapa dulu terlalu membang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peraturan anehh semua ,,, aku nyaris mati kela...</td>\n",
       "      <td>-1</td>\n",
       "      <td>peraturan anehh semua     aku nyaris mati kela...</td>\n",
       "      <td>peraturan aneh semua aku nyaris mati kelapan s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>1</td>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>semoga covid cepat berlallu..aminðŸ¤² \\nkaltim pu...</td>\n",
       "      <td>1</td>\n",
       "      <td>semoga covid cepat berlallu  aminðŸ¤²  kaltim pun...</td>\n",
       "      <td>semoga covid cepat berlallu aminðŸ¤² kaltim pun k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentimen  \\\n",
       "0  ya allah musnahkan lah virus corona dr muka bu...         0   \n",
       "1  sekarang saya malu  , kenapa dulu terlalu memb...        -1   \n",
       "2  peraturan anehh semua ,,, aku nyaris mati kela...        -1   \n",
       "3  saya selalu nunggu new normal biar saya segera...         1   \n",
       "4  semoga covid cepat berlallu..aminðŸ¤² \\nkaltim pu...         1   \n",
       "\n",
       "                                       text_wo_punct  \\\n",
       "0  ya allah musnahkan lah virus corona dr muka bu...   \n",
       "1  sekarang saya malu    kenapa dulu terlalu memb...   \n",
       "2  peraturan anehh semua     aku nyaris mati kela...   \n",
       "3  saya selalu nunggu new normal biar saya segera...   \n",
       "4  semoga covid cepat berlallu  aminðŸ¤²  kaltim pun...   \n",
       "\n",
       "                                         text_custom  \n",
       "0  ya allah musnahkan lah virus corona dr muka bu...  \n",
       "1  sekarang saya malu kenapa dulu terlalu membang...  \n",
       "2  peraturan aneh semua aku nyaris mati kelapan s...  \n",
       "3  saya selalu nunggu new normal biar saya segera...  \n",
       "4  semoga covid cepat berlallu aminðŸ¤² kaltim pun k...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_from = \"text_wo_punct\"\n",
    "# col_from = \"text\"\n",
    "col_save = \"text_custom\"\n",
    "def remove_(text):\n",
    "    # remove wkwk\n",
    "    text = re.sub(r'\\b(?=\\w*wk)\\w+', '', text)\n",
    "    # remove DIGIT\n",
    "    text = re.sub(r'([0-9])+', '', text)\n",
    "    # Hapus huruf >1 di akhir kata\n",
    "    text = re.sub(r'(.)\\1{1,}\\b', r'\\1', text)\n",
    "    # Hapus huruf >2 di kata\n",
    "    text = re.sub(r'(.)\\1{2,}', r'\\1', text)\n",
    "    # Hapus newline\n",
    "    text = text.replace('\\n', '')\n",
    "    return text\n",
    "\n",
    "df[col_save] = df[col_from].apply(lambda text: remove_(text))\n",
    "COL = col_save\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hapus emoji "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ad820e9e654beb9982432d389f8cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='replacing emojis...', max=1460.0, style=ProgressStyle(desâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentimen</th>\n",
       "      <th>text_wo_punct</th>\n",
       "      <th>text_custom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "      <td>ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sekarang saya malu  , kenapa dulu terlalu memb...</td>\n",
       "      <td>-1</td>\n",
       "      <td>sekarang saya malu    kenapa dulu terlalu memb...</td>\n",
       "      <td>sekarang saya malu kenapa dulu terlalu membang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peraturan anehh semua ,,, aku nyaris mati kela...</td>\n",
       "      <td>-1</td>\n",
       "      <td>peraturan anehh semua     aku nyaris mati kela...</td>\n",
       "      <td>peraturan aneh semua aku nyaris mati kelapan s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>1</td>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>semoga covid cepat berlallu..aminðŸ¤² \\nkaltim pu...</td>\n",
       "      <td>1</td>\n",
       "      <td>semoga covid cepat berlallu  aminðŸ¤²  kaltim pun...</td>\n",
       "      <td>semoga covid cepat berlallu amin 1F932  kaltim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentimen  \\\n",
       "0  ya allah musnahkan lah virus corona dr muka bu...         0   \n",
       "1  sekarang saya malu  , kenapa dulu terlalu memb...        -1   \n",
       "2  peraturan anehh semua ,,, aku nyaris mati kela...        -1   \n",
       "3  saya selalu nunggu new normal biar saya segera...         1   \n",
       "4  semoga covid cepat berlallu..aminðŸ¤² \\nkaltim pu...         1   \n",
       "\n",
       "                                       text_wo_punct  \\\n",
       "0  ya allah musnahkan lah virus corona dr muka bu...   \n",
       "1  sekarang saya malu    kenapa dulu terlalu memb...   \n",
       "2  peraturan anehh semua     aku nyaris mati kela...   \n",
       "3  saya selalu nunggu new normal biar saya segera...   \n",
       "4  semoga covid cepat berlallu  aminðŸ¤²  kaltim pun...   \n",
       "\n",
       "                                         text_custom  \n",
       "0  ya allah musnahkan lah virus corona dr muka bu...  \n",
       "1  sekarang saya malu kenapa dulu terlalu membang...  \n",
       "2  peraturan aneh semua aku nyaris mati kelapan s...  \n",
       "3  saya selalu nunggu new normal biar saya segera...  \n",
       "4  semoga covid cepat berlallu amin 1F932  kaltim...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# REPLACE EMOJIS\n",
    "col_from = \"text_custom\"\n",
    "col_save = \"text_custom\"\n",
    "\n",
    "def getEmojis():\n",
    "    emojis = {}\n",
    "    dfemo = pd.read_csv('data\\\\emoji_df.csv')\n",
    "    emokeys = dfemo.emoji.values\n",
    "    emoval = dfemo.codepoints\n",
    "    for i in range(len(emokeys)):\n",
    "        emojis[emokeys[i]] = emoval[i]\n",
    "    return emojis\n",
    "EMOJIS = getEmojis()\n",
    "\n",
    "def convert_emojis(text):\n",
    "    for emot in EMOJIS:\n",
    "        text = str.replace(text, emot, ' '+EMOJIS[emot]+' ')\n",
    "    return text\n",
    "def remove_(text, pbar):\n",
    "    \"\"\"custom function to remove ...\"\"\"\n",
    "    pbar.update(1)\n",
    "    return convert_emojis(text)\n",
    "\n",
    "with tqdm(total=len(df), desc=\"replacing emojis...\") as pbar:\n",
    "    df[col_save] = df[col_from].apply(lambda text: remove_(text, pbar))\n",
    "COL = col_save\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ganti kata singkatan\n",
    " - 'yg -> 'yang'\n",
    " - 'smg' -> 'semoga'\n",
    " - 'tdk', 'g', 'ga', 'ngga', dll -> 'tidak'\n",
    " - dll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    }
   ],
   "source": [
    "singkatan = {'find':[], 'replace':[]}\n",
    "with open('data\\\\singkat.txt') as f:\n",
    "    for t in f.read().split('\\n'):\n",
    "        singkatan['find'].append(t.split(',')[0].strip())\n",
    "        singkatan['replace'].append(t.split(',')[1].strip())\n",
    "print(singkatan['find'].index('yg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentimen</th>\n",
       "      <th>text_wo_punct</th>\n",
       "      <th>text_custom</th>\n",
       "      <th>text_rmvcustom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "      <td>ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "      <td>ya allah musnahkan lah virus corona  dari  muk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sekarang saya malu  , kenapa dulu terlalu memb...</td>\n",
       "      <td>-1</td>\n",
       "      <td>sekarang saya malu    kenapa dulu terlalu memb...</td>\n",
       "      <td>sekarang saya malu kenapa dulu terlalu membang...</td>\n",
       "      <td>sekarang saya malu kenapa dulu terlalu membang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peraturan anehh semua ,,, aku nyaris mati kela...</td>\n",
       "      <td>-1</td>\n",
       "      <td>peraturan anehh semua     aku nyaris mati kela...</td>\n",
       "      <td>peraturan aneh semua aku nyaris mati kelapan s...</td>\n",
       "      <td>peraturan aneh semua  saya  nyaris mati kelapa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>1</td>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>semoga covid cepat berlallu..aminðŸ¤² \\nkaltim pu...</td>\n",
       "      <td>1</td>\n",
       "      <td>semoga covid cepat berlallu  aminðŸ¤²  kaltim pun...</td>\n",
       "      <td>semoga covid cepat berlallu amin 1F932  kaltim...</td>\n",
       "      <td>semoga covid cepat berlallu amin 1F932  kaltim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentimen  \\\n",
       "0  ya allah musnahkan lah virus corona dr muka bu...         0   \n",
       "1  sekarang saya malu  , kenapa dulu terlalu memb...        -1   \n",
       "2  peraturan anehh semua ,,, aku nyaris mati kela...        -1   \n",
       "3  saya selalu nunggu new normal biar saya segera...         1   \n",
       "4  semoga covid cepat berlallu..aminðŸ¤² \\nkaltim pu...         1   \n",
       "\n",
       "                                       text_wo_punct  \\\n",
       "0  ya allah musnahkan lah virus corona dr muka bu...   \n",
       "1  sekarang saya malu    kenapa dulu terlalu memb...   \n",
       "2  peraturan anehh semua     aku nyaris mati kela...   \n",
       "3  saya selalu nunggu new normal biar saya segera...   \n",
       "4  semoga covid cepat berlallu  aminðŸ¤²  kaltim pun...   \n",
       "\n",
       "                                         text_custom  \\\n",
       "0  ya allah musnahkan lah virus corona dr muka bu...   \n",
       "1  sekarang saya malu kenapa dulu terlalu membang...   \n",
       "2  peraturan aneh semua aku nyaris mati kelapan s...   \n",
       "3  saya selalu nunggu new normal biar saya segera...   \n",
       "4  semoga covid cepat berlallu amin 1F932  kaltim...   \n",
       "\n",
       "                                      text_rmvcustom  \n",
       "0  ya allah musnahkan lah virus corona  dari  muk...  \n",
       "1  sekarang saya malu kenapa dulu terlalu membang...  \n",
       "2  peraturan aneh semua  saya  nyaris mati kelapa...  \n",
       "3  saya selalu nunggu new normal biar saya segera...  \n",
       "4  semoga covid cepat berlallu amin 1F932  kaltim...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace kata yang disingkat\n",
    "col_from = \"text_custom\"\n",
    "col_save = \"text_rmvcustom\"\n",
    "def remove_(text):\n",
    "    \"\"\"custom function to remove the \"\"\"\n",
    "    for i in range(len(singkatan['replace'])):\n",
    "#         if re.search(r'\\b('+singkatan['find'][i]+r')\\b', text):\n",
    "#             print(text)\n",
    "        text = re.sub(r'\\b('+singkatan['find'][i]+r')\\b', ' '+singkatan['replace'][i]+' ', text)\n",
    "    return text\n",
    "\n",
    "df[col_save] = df[col_from].apply(lambda text: remove_(text))\n",
    "COL = col_save\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yang', 'untuk', 'pada', 'ke', 'para', 'namun', 'menurut', 'antara', 'dia', 'dua', 'ia', 'seperti', 'jika', 'jika', 'sehingga', 'kembali', 'dan', 'tidak', 'ini', 'karena', 'kepada', 'oleh', 'saat', 'harus', 'sementara', 'setelah', 'belum', 'kami', 'sekitar', 'bagi', 'serta', 'di', 'dari', 'telah', 'sebagai', 'masih', 'hal', 'ketika', 'adalah', 'itu', 'dalam', 'bisa', 'bahwa', 'atau', 'hanya', 'kita', 'dengan', 'akan', 'juga', 'ada', 'mereka', 'sudah', 'saya', 'terhadap', 'secara', 'agar', 'lain', 'anda', 'begitu', 'mengapa', 'kenapa', 'yaitu', 'yakni', 'daripada', 'itulah', 'lagi', 'maka', 'tentang', 'demi', 'dimana', 'kemana', 'pula', 'sambil', 'sebelum', 'sesudah', 'supaya', 'guna', 'kah', 'pun', 'sampai', 'sedangkan', 'selagi', 'sementara', 'tetapi', 'apakah', 'kecuali', 'sebab', 'selain', 'seolah', 'seraya', 'seterusnya', 'tanpa', 'agak', 'boleh', 'dapat', 'dsb', 'dst', 'dll', 'dahulu', 'dulunya', 'anu', 'demikian', 'tapi', 'ingin', 'juga', 'nggak', 'mari', 'nanti', 'melainkan', 'oh', 'ok', 'seharusnya', 'sebetulnya', 'setiap', 'setidaknya', 'sesuatu', 'pasti', 'saja', 'toh', 'ya', 'walau', 'tolong', 'tentu', 'amat', 'apalagi', 'bagaimanapun', 'dengan', 'eh', 'ah', 'jadi', 'psb', 'aku', 'biar', 'lah', 'dr', 'yg', 'nya', 'aja', 'klo', 'kalo', 'kalau', 'dah', 'tuh', 'mah', 'kan', 'nah', 'coy', 'emang', 'emg', 'memang', 'kale', 'kali', 'pa', 'pak', 'bpk', 'pk', 'tah', 'mah', 'd', 'kita', 'dah', 'dih', 'kamu', 'doang', 'ah']\n"
     ]
    }
   ],
   "source": [
    "# Stopwords removal\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    " \n",
    "factory = StopWordRemoverFactory()\n",
    "# stopword = factory.create_stop_word_remover()\n",
    "# print(factory.get_stop_words())\n",
    "\n",
    "# STOPWORDS = set(stopwords.words('indonesian'))\n",
    "STOPWORDS = factory.get_stop_words()\n",
    "with open('data\\\\tambahan_stopwords.txt') as f:\n",
    "    for t in re.sub(r\"[\\',]\", '', f.read()).split():\n",
    "        STOPWORDS.append(t) \n",
    "print(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS.remove('kenapa')\n",
    "STOPWORDS.remove('apakah')\n",
    "# STOPWORDS.remove('apa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentimen</th>\n",
       "      <th>text_wo_punct</th>\n",
       "      <th>text_custom</th>\n",
       "      <th>text_rmvcustom</th>\n",
       "      <th>text_wo_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "      <td>ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "      <td>ya allah musnahkan lah virus corona  dari  muk...</td>\n",
       "      <td>allah musnahkan virus corona   muka bumi menja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sekarang saya malu  , kenapa dulu terlalu memb...</td>\n",
       "      <td>-1</td>\n",
       "      <td>sekarang saya malu    kenapa dulu terlalu memb...</td>\n",
       "      <td>sekarang saya malu kenapa dulu terlalu membang...</td>\n",
       "      <td>sekarang saya malu kenapa dulu terlalu membang...</td>\n",
       "      <td>sekarang malu kenapa dulu terlalu membanggakan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peraturan anehh semua ,,, aku nyaris mati kela...</td>\n",
       "      <td>-1</td>\n",
       "      <td>peraturan anehh semua     aku nyaris mati kela...</td>\n",
       "      <td>peraturan aneh semua aku nyaris mati kelapan s...</td>\n",
       "      <td>peraturan aneh semua  saya  nyaris mati kelapa...</td>\n",
       "      <td>peraturan aneh semua   nyaris mati kelapan sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>1</td>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>selalu nunggu new normal segera melangsungkan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>semoga covid cepat berlallu..aminðŸ¤² \\nkaltim pu...</td>\n",
       "      <td>1</td>\n",
       "      <td>semoga covid cepat berlallu  aminðŸ¤²  kaltim pun...</td>\n",
       "      <td>semoga covid cepat berlallu amin 1F932  kaltim...</td>\n",
       "      <td>semoga covid cepat berlallu amin 1F932  kaltim...</td>\n",
       "      <td>semoga covid cepat berlallu amin 1F932  kaltim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentimen  \\\n",
       "0  ya allah musnahkan lah virus corona dr muka bu...         0   \n",
       "1  sekarang saya malu  , kenapa dulu terlalu memb...        -1   \n",
       "2  peraturan anehh semua ,,, aku nyaris mati kela...        -1   \n",
       "3  saya selalu nunggu new normal biar saya segera...         1   \n",
       "4  semoga covid cepat berlallu..aminðŸ¤² \\nkaltim pu...         1   \n",
       "\n",
       "                                       text_wo_punct  \\\n",
       "0  ya allah musnahkan lah virus corona dr muka bu...   \n",
       "1  sekarang saya malu    kenapa dulu terlalu memb...   \n",
       "2  peraturan anehh semua     aku nyaris mati kela...   \n",
       "3  saya selalu nunggu new normal biar saya segera...   \n",
       "4  semoga covid cepat berlallu  aminðŸ¤²  kaltim pun...   \n",
       "\n",
       "                                         text_custom  \\\n",
       "0  ya allah musnahkan lah virus corona dr muka bu...   \n",
       "1  sekarang saya malu kenapa dulu terlalu membang...   \n",
       "2  peraturan aneh semua aku nyaris mati kelapan s...   \n",
       "3  saya selalu nunggu new normal biar saya segera...   \n",
       "4  semoga covid cepat berlallu amin 1F932  kaltim...   \n",
       "\n",
       "                                      text_rmvcustom  \\\n",
       "0  ya allah musnahkan lah virus corona  dari  muk...   \n",
       "1  sekarang saya malu kenapa dulu terlalu membang...   \n",
       "2  peraturan aneh semua  saya  nyaris mati kelapa...   \n",
       "3  saya selalu nunggu new normal biar saya segera...   \n",
       "4  semoga covid cepat berlallu amin 1F932  kaltim...   \n",
       "\n",
       "                                        text_wo_stop  \n",
       "0  allah musnahkan virus corona   muka bumi menja...  \n",
       "1  sekarang malu kenapa dulu terlalu membanggakan...  \n",
       "2  peraturan aneh semua   nyaris mati kelapan sam...  \n",
       "3  selalu nunggu new normal segera melangsungkan ...  \n",
       "4  semoga covid cepat berlallu amin 1F932  kaltim...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_from = \"text_rmvcustom\"\n",
    "col_save = \"text_wo_stop\"\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split(' ') if word not in STOPWORDS])\n",
    "\n",
    "df[col_save] = df[col_from].apply(lambda text: remove_stopwords(text))\n",
    "COL = col_save\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36eb4c6319b45c28d3af58d27f8ef48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='stemming...', max=1460.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentimen</th>\n",
       "      <th>text_wo_punct</th>\n",
       "      <th>text_custom</th>\n",
       "      <th>text_rmvcustom</th>\n",
       "      <th>text_wo_stop</th>\n",
       "      <th>text_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "      <td>ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "      <td>ya allah musnahkan lah virus corona  dari  muk...</td>\n",
       "      <td>allah musnahkan virus corona   muka bumi menja...</td>\n",
       "      <td>allah musnah virus corona   muka bumi jalan hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sekarang saya malu  , kenapa dulu terlalu memb...</td>\n",
       "      <td>-1</td>\n",
       "      <td>sekarang saya malu    kenapa dulu terlalu memb...</td>\n",
       "      <td>sekarang saya malu kenapa dulu terlalu membang...</td>\n",
       "      <td>sekarang saya malu kenapa dulu terlalu membang...</td>\n",
       "      <td>sekarang malu kenapa dulu terlalu membanggakan...</td>\n",
       "      <td>sekarang malu kenapa dulu terlalu bangga belia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peraturan anehh semua ,,, aku nyaris mati kela...</td>\n",
       "      <td>-1</td>\n",
       "      <td>peraturan anehh semua     aku nyaris mati kela...</td>\n",
       "      <td>peraturan aneh semua aku nyaris mati kelapan s...</td>\n",
       "      <td>peraturan aneh semua  saya  nyaris mati kelapa...</td>\n",
       "      <td>peraturan aneh semua   nyaris mati kelapan sam...</td>\n",
       "      <td>atur aneh semua   nyaris mati kelap sama anak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>1</td>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>selalu nunggu new normal segera melangsungkan ...</td>\n",
       "      <td>selalu nunggu new normal segera langsung nikah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>semoga covid cepat berlallu..aminðŸ¤² \\nkaltim pu...</td>\n",
       "      <td>1</td>\n",
       "      <td>semoga covid cepat berlallu  aminðŸ¤²  kaltim pun...</td>\n",
       "      <td>semoga covid cepat berlallu amin 1F932  kaltim...</td>\n",
       "      <td>semoga covid cepat berlallu amin 1F932  kaltim...</td>\n",
       "      <td>semoga covid cepat berlallu amin 1F932  kaltim...</td>\n",
       "      <td>moga covid cepat berlallu amin 1f932  kaltim s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentimen  \\\n",
       "0  ya allah musnahkan lah virus corona dr muka bu...         0   \n",
       "1  sekarang saya malu  , kenapa dulu terlalu memb...        -1   \n",
       "2  peraturan anehh semua ,,, aku nyaris mati kela...        -1   \n",
       "3  saya selalu nunggu new normal biar saya segera...         1   \n",
       "4  semoga covid cepat berlallu..aminðŸ¤² \\nkaltim pu...         1   \n",
       "\n",
       "                                       text_wo_punct  \\\n",
       "0  ya allah musnahkan lah virus corona dr muka bu...   \n",
       "1  sekarang saya malu    kenapa dulu terlalu memb...   \n",
       "2  peraturan anehh semua     aku nyaris mati kela...   \n",
       "3  saya selalu nunggu new normal biar saya segera...   \n",
       "4  semoga covid cepat berlallu  aminðŸ¤²  kaltim pun...   \n",
       "\n",
       "                                         text_custom  \\\n",
       "0  ya allah musnahkan lah virus corona dr muka bu...   \n",
       "1  sekarang saya malu kenapa dulu terlalu membang...   \n",
       "2  peraturan aneh semua aku nyaris mati kelapan s...   \n",
       "3  saya selalu nunggu new normal biar saya segera...   \n",
       "4  semoga covid cepat berlallu amin 1F932  kaltim...   \n",
       "\n",
       "                                      text_rmvcustom  \\\n",
       "0  ya allah musnahkan lah virus corona  dari  muk...   \n",
       "1  sekarang saya malu kenapa dulu terlalu membang...   \n",
       "2  peraturan aneh semua  saya  nyaris mati kelapa...   \n",
       "3  saya selalu nunggu new normal biar saya segera...   \n",
       "4  semoga covid cepat berlallu amin 1F932  kaltim...   \n",
       "\n",
       "                                        text_wo_stop  \\\n",
       "0  allah musnahkan virus corona   muka bumi menja...   \n",
       "1  sekarang malu kenapa dulu terlalu membanggakan...   \n",
       "2  peraturan aneh semua   nyaris mati kelapan sam...   \n",
       "3  selalu nunggu new normal segera melangsungkan ...   \n",
       "4  semoga covid cepat berlallu amin 1F932  kaltim...   \n",
       "\n",
       "                                        text_stemmed  \n",
       "0  allah musnah virus corona   muka bumi jalan hi...  \n",
       "1  sekarang malu kenapa dulu terlalu bangga belia...  \n",
       "2  atur aneh semua   nyaris mati kelap sama anak ...  \n",
       "3  selalu nunggu new normal segera langsung nikah...  \n",
       "4  moga covid cepat berlallu amin 1f932  kaltim s...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stemming\n",
    "# from tqdm.notebook import trange, tqdm\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "col_from = \"text_wo_stop\"\n",
    "col_save = \"text_stemmed\"\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "def stem_words(text, pbar):\n",
    "    pbar.update(1)\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split(' ')])\n",
    "\n",
    "with tqdm(total=len(df), desc=\"stemming...\") as pbar:\n",
    "    df[col_save] = df[col_from].apply(lambda text: stem_words(text, pbar))\n",
    "COL = col_save\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most freq words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('normal', 484),\n",
       " ('new', 408),\n",
       " ('rakyat', 236),\n",
       " ('indonesia', 229),\n",
       " ('perintah', 227)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for text in df[\"text_stemmed\"].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "        \n",
    "cnt.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentimen</th>\n",
       "      <th>text_wo_punct</th>\n",
       "      <th>text_custom</th>\n",
       "      <th>text_rmvcustom</th>\n",
       "      <th>text_wo_stop</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_wo_stopfreq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "      <td>ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "      <td>ya allah musnahkan lah virus corona  dari  muk...</td>\n",
       "      <td>allah musnahkan virus corona   muka bumi menja...</td>\n",
       "      <td>allah musnah virus corona   muka bumi jalan hi...</td>\n",
       "      <td>allah musnah virus corona   muka bumi jalan hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sekarang saya malu  , kenapa dulu terlalu memb...</td>\n",
       "      <td>-1</td>\n",
       "      <td>sekarang saya malu    kenapa dulu terlalu memb...</td>\n",
       "      <td>sekarang saya malu kenapa dulu terlalu membang...</td>\n",
       "      <td>sekarang saya malu kenapa dulu terlalu membang...</td>\n",
       "      <td>sekarang malu kenapa dulu terlalu membanggakan...</td>\n",
       "      <td>sekarang malu kenapa dulu terlalu bangga belia...</td>\n",
       "      <td>sekarang malu kenapa dulu terlalu bangga belia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peraturan anehh semua ,,, aku nyaris mati kela...</td>\n",
       "      <td>-1</td>\n",
       "      <td>peraturan anehh semua     aku nyaris mati kela...</td>\n",
       "      <td>peraturan aneh semua aku nyaris mati kelapan s...</td>\n",
       "      <td>peraturan aneh semua  saya  nyaris mati kelapa...</td>\n",
       "      <td>peraturan aneh semua   nyaris mati kelapan sam...</td>\n",
       "      <td>atur aneh semua   nyaris mati kelap sama anak ...</td>\n",
       "      <td>atur aneh semua   nyaris mati kelap sama anak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>1</td>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>selalu nunggu new normal segera melangsungkan ...</td>\n",
       "      <td>selalu nunggu new normal segera langsung nikah...</td>\n",
       "      <td>selalu nunggu segera langsung nikah tunggu doa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>semoga covid cepat berlallu..aminðŸ¤² \\nkaltim pu...</td>\n",
       "      <td>1</td>\n",
       "      <td>semoga covid cepat berlallu  aminðŸ¤²  kaltim pun...</td>\n",
       "      <td>semoga covid cepat berlallu amin 1F932  kaltim...</td>\n",
       "      <td>semoga covid cepat berlallu amin 1F932  kaltim...</td>\n",
       "      <td>semoga covid cepat berlallu amin 1F932  kaltim...</td>\n",
       "      <td>moga covid cepat berlallu amin 1f932  kaltim s...</td>\n",
       "      <td>moga covid cepat berlallu amin 1f932  kaltim s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentimen  \\\n",
       "0  ya allah musnahkan lah virus corona dr muka bu...         0   \n",
       "1  sekarang saya malu  , kenapa dulu terlalu memb...        -1   \n",
       "2  peraturan anehh semua ,,, aku nyaris mati kela...        -1   \n",
       "3  saya selalu nunggu new normal biar saya segera...         1   \n",
       "4  semoga covid cepat berlallu..aminðŸ¤² \\nkaltim pu...         1   \n",
       "\n",
       "                                       text_wo_punct  \\\n",
       "0  ya allah musnahkan lah virus corona dr muka bu...   \n",
       "1  sekarang saya malu    kenapa dulu terlalu memb...   \n",
       "2  peraturan anehh semua     aku nyaris mati kela...   \n",
       "3  saya selalu nunggu new normal biar saya segera...   \n",
       "4  semoga covid cepat berlallu  aminðŸ¤²  kaltim pun...   \n",
       "\n",
       "                                         text_custom  \\\n",
       "0  ya allah musnahkan lah virus corona dr muka bu...   \n",
       "1  sekarang saya malu kenapa dulu terlalu membang...   \n",
       "2  peraturan aneh semua aku nyaris mati kelapan s...   \n",
       "3  saya selalu nunggu new normal biar saya segera...   \n",
       "4  semoga covid cepat berlallu amin 1F932  kaltim...   \n",
       "\n",
       "                                      text_rmvcustom  \\\n",
       "0  ya allah musnahkan lah virus corona  dari  muk...   \n",
       "1  sekarang saya malu kenapa dulu terlalu membang...   \n",
       "2  peraturan aneh semua  saya  nyaris mati kelapa...   \n",
       "3  saya selalu nunggu new normal biar saya segera...   \n",
       "4  semoga covid cepat berlallu amin 1F932  kaltim...   \n",
       "\n",
       "                                        text_wo_stop  \\\n",
       "0  allah musnahkan virus corona   muka bumi menja...   \n",
       "1  sekarang malu kenapa dulu terlalu membanggakan...   \n",
       "2  peraturan aneh semua   nyaris mati kelapan sam...   \n",
       "3  selalu nunggu new normal segera melangsungkan ...   \n",
       "4  semoga covid cepat berlallu amin 1F932  kaltim...   \n",
       "\n",
       "                                        text_stemmed  \\\n",
       "0  allah musnah virus corona   muka bumi jalan hi...   \n",
       "1  sekarang malu kenapa dulu terlalu bangga belia...   \n",
       "2  atur aneh semua   nyaris mati kelap sama anak ...   \n",
       "3  selalu nunggu new normal segera langsung nikah...   \n",
       "4  moga covid cepat berlallu amin 1f932  kaltim s...   \n",
       "\n",
       "                                    text_wo_stopfreq  \n",
       "0  allah musnah virus corona   muka bumi jalan hi...  \n",
       "1  sekarang malu kenapa dulu terlalu bangga belia...  \n",
       "2  atur aneh semua   nyaris mati kelap sama anak ...  \n",
       "3  selalu nunggu segera langsung nikah tunggu doa...  \n",
       "4  moga covid cepat berlallu amin 1f932  kaltim s...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hapus most freq words\n",
    "FREQWORDS = set([w for (w, wc) in cnt.most_common(2)])\n",
    "def remove_freqwords(text):\n",
    "    \"\"\"custom function to remove the frequent words\"\"\"\n",
    "    return \" \".join([word for word in str(text).split(' ') if word not in FREQWORDS])\n",
    "\n",
    "df[\"text_wo_stopfreq\"] = df[\"text_stemmed\"].apply(lambda text: remove_freqwords(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least freq words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dermawan', 1), ('subsidi', 1), ('berakir', 1), ('gerah', 1), ('ekonmi', 1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for text in df[\"text_stemmed\"].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "        \n",
    "cnt.most_common()[:-5-1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentimen</th>\n",
       "      <th>text_wo_punct</th>\n",
       "      <th>text_custom</th>\n",
       "      <th>text_rmvcustom</th>\n",
       "      <th>text_wo_stop</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_wo_stopfreq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "      <td>ya allah musnahkan lah virus corona dr muka bu...</td>\n",
       "      <td>ya allah musnahkan lah virus corona  dari  muk...</td>\n",
       "      <td>allah musnahkan virus corona   muka bumi menja...</td>\n",
       "      <td>allah musnah virus corona   muka bumi jalan hi...</td>\n",
       "      <td>allah musnah virus corona   muka bumi jalan hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sekarang saya malu  , kenapa dulu terlalu memb...</td>\n",
       "      <td>-1</td>\n",
       "      <td>sekarang saya malu    kenapa dulu terlalu memb...</td>\n",
       "      <td>sekarang saya malu kenapa dulu terlalu membang...</td>\n",
       "      <td>sekarang saya malu kenapa dulu terlalu membang...</td>\n",
       "      <td>sekarang malu kenapa dulu terlalu membanggakan...</td>\n",
       "      <td>sekarang malu kenapa dulu terlalu bangga belia...</td>\n",
       "      <td>sekarang malu kenapa dulu terlalu bangga belia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peraturan anehh semua ,,, aku nyaris mati kela...</td>\n",
       "      <td>-1</td>\n",
       "      <td>peraturan anehh semua     aku nyaris mati kela...</td>\n",
       "      <td>peraturan aneh semua aku nyaris mati kelapan s...</td>\n",
       "      <td>peraturan aneh semua  saya  nyaris mati kelapa...</td>\n",
       "      <td>peraturan aneh semua   nyaris mati kelapan sam...</td>\n",
       "      <td>atur aneh semua   nyaris mati kelap sama anak ...</td>\n",
       "      <td>atur aneh semua   nyaris mati kelap sama anak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>1</td>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>saya selalu nunggu new normal biar saya segera...</td>\n",
       "      <td>selalu nunggu new normal segera melangsungkan ...</td>\n",
       "      <td>selalu nunggu new normal segera langsung nikah...</td>\n",
       "      <td>selalu nunggu segera langsung nikah tunggu doa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>semoga covid cepat berlallu..aminðŸ¤² \\nkaltim pu...</td>\n",
       "      <td>1</td>\n",
       "      <td>semoga covid cepat berlallu  aminðŸ¤²  kaltim pun...</td>\n",
       "      <td>semoga covid cepat berlallu amin 1F932  kaltim...</td>\n",
       "      <td>semoga covid cepat berlallu amin 1F932  kaltim...</td>\n",
       "      <td>semoga covid cepat berlallu amin 1F932  kaltim...</td>\n",
       "      <td>moga covid cepat berlallu amin 1f932  kaltim s...</td>\n",
       "      <td>moga covid cepat berlallu amin 1f932  kaltim s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentimen  \\\n",
       "0  ya allah musnahkan lah virus corona dr muka bu...         0   \n",
       "1  sekarang saya malu  , kenapa dulu terlalu memb...        -1   \n",
       "2  peraturan anehh semua ,,, aku nyaris mati kela...        -1   \n",
       "3  saya selalu nunggu new normal biar saya segera...         1   \n",
       "4  semoga covid cepat berlallu..aminðŸ¤² \\nkaltim pu...         1   \n",
       "\n",
       "                                       text_wo_punct  \\\n",
       "0  ya allah musnahkan lah virus corona dr muka bu...   \n",
       "1  sekarang saya malu    kenapa dulu terlalu memb...   \n",
       "2  peraturan anehh semua     aku nyaris mati kela...   \n",
       "3  saya selalu nunggu new normal biar saya segera...   \n",
       "4  semoga covid cepat berlallu  aminðŸ¤²  kaltim pun...   \n",
       "\n",
       "                                         text_custom  \\\n",
       "0  ya allah musnahkan lah virus corona dr muka bu...   \n",
       "1  sekarang saya malu kenapa dulu terlalu membang...   \n",
       "2  peraturan aneh semua aku nyaris mati kelapan s...   \n",
       "3  saya selalu nunggu new normal biar saya segera...   \n",
       "4  semoga covid cepat berlallu amin 1F932  kaltim...   \n",
       "\n",
       "                                      text_rmvcustom  \\\n",
       "0  ya allah musnahkan lah virus corona  dari  muk...   \n",
       "1  sekarang saya malu kenapa dulu terlalu membang...   \n",
       "2  peraturan aneh semua  saya  nyaris mati kelapa...   \n",
       "3  saya selalu nunggu new normal biar saya segera...   \n",
       "4  semoga covid cepat berlallu amin 1F932  kaltim...   \n",
       "\n",
       "                                        text_wo_stop  \\\n",
       "0  allah musnahkan virus corona   muka bumi menja...   \n",
       "1  sekarang malu kenapa dulu terlalu membanggakan...   \n",
       "2  peraturan aneh semua   nyaris mati kelapan sam...   \n",
       "3  selalu nunggu new normal segera melangsungkan ...   \n",
       "4  semoga covid cepat berlallu amin 1F932  kaltim...   \n",
       "\n",
       "                                        text_stemmed  \\\n",
       "0  allah musnah virus corona   muka bumi jalan hi...   \n",
       "1  sekarang malu kenapa dulu terlalu bangga belia...   \n",
       "2  atur aneh semua   nyaris mati kelap sama anak ...   \n",
       "3  selalu nunggu new normal segera langsung nikah...   \n",
       "4  moga covid cepat berlallu amin 1f932  kaltim s...   \n",
       "\n",
       "                                    text_wo_stopfreq  \n",
       "0  allah musnah virus corona   muka bumi jalan hi...  \n",
       "1  sekarang malu kenapa dulu terlalu bangga belia...  \n",
       "2  atur aneh semua   nyaris mati kelap sama anak ...  \n",
       "3  selalu nunggu segera langsung nikah tunggu doa...  \n",
       "4  moga covid cepat berlallu amin 1f932  kaltim s...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the two columns which are no more needed \n",
    "# df.drop([\"text_wo_punct\", \"text_wo_stop\"], axis=1, inplace=True)\n",
    "\n",
    "n_rare_words = 100\n",
    "RAREWORDS = set([w for (w, wc) in cnt.most_common()[:-n_rare_words-1:-1]])\n",
    "def remove_rarewords(text):\n",
    "    \"\"\"custom function to remove the rare words\"\"\"\n",
    "    return \" \".join([word for word in str(text).split(' ') if word not in RAREWORDS])\n",
    "\n",
    "df[\"text_wo_stopfreq\"] = df[\"text_wo_stopfreq\"].apply(lambda text: remove_rarewords(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfbc = df.copy()\n",
    "# df = pd.merge(train, test, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COL = \"text_wo_emoji\"\n",
    "COL = 'text_wo_stopfreq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_wo_stopfreq\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1460, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(COL)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[:len(train)]\n",
    "# df[len(train):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF, Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=3, max_df=4.0, ngram_range=(1, 2))\n",
    "features = tfidf.fit_transform(df[COL].values)\n",
    "df2 = pd.DataFrame(features.todense(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 1803)\n"
     ]
    }
   ],
   "source": [
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['y'] = df['sentimen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split test with equal number of class,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test0 = df[df.y==-1].sample(60)\n",
    "# test1 = df[df.y==0].sample(60)\n",
    "# test2 = df[df.y==1].sample(60)\n",
    "# train=df[~df.isin(test0)&~df.isin(test1)&~df.isin(test2)].dropna()\n",
    "# test = pd.merge(test0, test1, how='outer')\n",
    "# test = pd.merge(test, test2, how='outer')\n",
    "# test = test.sample(len(test))\n",
    "# print(train.y.value_counts())\n",
    "# print(test.y.value_counts())\n",
    "\n",
    "# dftrain = df2[:len(train)]\n",
    "# dftest = df2[len(train):]\n",
    "# X_train = dftrain.drop(['y'], axis=1)\n",
    "# y_train = dftrain['y']\n",
    "# X_test = dftest.drop(['y'], axis=1)\n",
    "# y_test = dftest['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### or split randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df2.drop(['y'], axis=1), df2[['y']], test_size=0.25, random_state=555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6273972602739726\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1      0.671     0.723     0.696       155\n",
      "           0      0.586     0.586     0.586       128\n",
      "           1      0.600     0.512     0.553        82\n",
      "\n",
      "    accuracy                          0.627       365\n",
      "   macro avg      0.619     0.607     0.611       365\n",
      "weighted avg      0.625     0.627     0.625       365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "rgs = LogisticRegression(max_iter=600, \n",
    "                         C=1.65,\n",
    "                         solver='lbfgs',\n",
    "                         class_weight='balanced',\n",
    "                         n_jobs=-1)\n",
    "\n",
    "rgs.fit(X_train, y_train.values.ravel())\n",
    "y_pred = rgs.predict(X_test)\n",
    "print(rgs.score(X_test, y_test))\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6277777777777778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0      0.548     0.850     0.667        60\n",
      "         0.0      0.618     0.567     0.591        60\n",
      "         1.0      0.875     0.467     0.609        60\n",
      "\n",
      "    accuracy                          0.628       180\n",
      "   macro avg      0.681     0.628     0.622       180\n",
      "weighted avg      0.681     0.628     0.622       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(max_iter=-1, \n",
    "            C=1000,\n",
    "#             gamma=0.01,\n",
    "            kernel='rbf')\n",
    "# clf = svm.NuSVC(kernel='poly')\n",
    "# acc = cross_val_score(clf, X, Y, cv=4)\n",
    "clf.fit(X_train, y_train.values.ravel())\n",
    "y_pred = clf.predict(X_test)\n",
    "print(clf.score(X_test, y_test))\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0      0.559     0.867     0.680        60\n",
      "         0.0      0.623     0.550     0.584        60\n",
      "         1.0      0.853     0.483     0.617        60\n",
      "\n",
      "    accuracy                          0.633       180\n",
      "   macro avg      0.678     0.633     0.627       180\n",
      "weighted avg      0.678     0.633     0.627       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "clf = MultinomialNB(alpha=0.25)\n",
    "clf.fit(X_train, y_train.values.ravel())\n",
    "y_pred = clf.predict(X_test)\n",
    "print(clf.score(X_test, y_test))\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF, Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df=3, max_df=0.5, ngram_range=(1, 1))\n",
    "features = tfidf.fit_transform(df[COL].values)\n",
    "dfuni = pd.DataFrame(features.todense(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 1218)\n"
     ]
    }
   ],
   "source": [
    "print(dfuni.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfuni['y'] = df['sentimen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfunitrain = dfuni[:len(train)]\n",
    "dfunitest = dfuni[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unitrain = dfunitrain.drop(['y'], axis=1)\n",
    "y_unitrain = dfunitrain['y']\n",
    "X_unitest = dfunitest.drop(['y'], axis=1)\n",
    "y_unitest = dfunitest['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6277777777777778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0      0.558     0.717     0.628        60\n",
      "         0.0      0.653     0.533     0.587        60\n",
      "         1.0      0.704     0.633     0.667        60\n",
      "\n",
      "    accuracy                          0.628       180\n",
      "   macro avg      0.638     0.628     0.627       180\n",
      "weighted avg      0.638     0.628     0.627       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rgs = LogisticRegression(max_iter=600, \n",
    "                         C=1.65,\n",
    "                         solver='lbfgs',\n",
    "                         class_weight='balanced',\n",
    "                         n_jobs=-1)\n",
    "\n",
    "rgs.fit(X_unitrain, y_unitrain.values.ravel())\n",
    "y_unipred = rgs.predict(X_unitest)\n",
    "print('Accuracy:', rgs.score(X_unitest, y_unitest))\n",
    "print(metrics.classification_report(y_unitest, y_unipred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5944444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0      0.517     0.767     0.617        60\n",
      "         0.0      0.571     0.533     0.552        60\n",
      "         1.0      0.829     0.483     0.611        60\n",
      "\n",
      "    accuracy                          0.594       180\n",
      "   macro avg      0.639     0.594     0.593       180\n",
      "weighted avg      0.639     0.594     0.593       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(max_iter=-1, \n",
    "            C=1000,\n",
    "#             gamma=0.01,\n",
    "            kernel='rbf')\n",
    "# clf = svm.NuSVC(kernel='poly')\n",
    "clf.fit(X_unitrain, y_unitrain.values.ravel())\n",
    "y_unipred = clf.predict(X_unitest)\n",
    "print(clf.score(X_unitest, y_unitest))\n",
    "print(metrics.classification_report(y_unitest, y_unipred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0      0.521     0.833     0.641        60\n",
      "         0.0      0.627     0.533     0.577        60\n",
      "         1.0      0.879     0.483     0.624        60\n",
      "\n",
      "    accuracy                          0.617       180\n",
      "   macro avg      0.676     0.617     0.614       180\n",
      "weighted avg      0.676     0.617     0.614       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=0.25)\n",
    "clf.fit(X_unitrain, y_unitrain.values.ravel())\n",
    "y_unipred = clf.predict(X_unitest)\n",
    "print(clf.score(X_unitest, y_unitest))\n",
    "print(metrics.classification_report(y_unitest, y_unipred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
